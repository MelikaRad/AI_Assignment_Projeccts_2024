{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c3e8fb; padding: 10px; color: #144d84;\">\n",
    "<b>Exercise 3) Flower Classification</b><br>\n",
    "Using the flower dataset, write a classifier to identify these flowers.\n",
    "\n",
    "The network structure should be similar to VGG, meaning each block should have twice as many filters as the previous one, all convolutional layers should be 3x3 with 'same' padding, and all pooling layers should be 2x2.\n",
    "Use batch normalization.\n",
    "During training, use the ReduceLROnPlateau callback with a patience of 5 epochs and the EarlyStopping callback with a patience of 10 epochs.\n",
    "Use the restore_best_weights=True parameter in the EarlyStopping callback. What does this parameter do?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRa1BZc52Fjd"
   },
   "source": [
    "# phase 1. : data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cjpVnrekTeII"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# flowers_root = tf.keras.utils.get_file(\n",
    "#     'flower_photos',\n",
    "#     'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "#     untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzyOKly7cu96",
    "outputId": "4bdce430-ac2f-4f47-8604-ec79dd2c9c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-27 21:29:26--  https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.207, 142.251.10.207, 142.251.12.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 228813984 (218M) [application/x-compressed-tar]\n",
      "Saving to: ‘flower_photos.tgz’\n",
      "\n",
      "flower_photos.tgz   100%[===================>] 218.21M  20.9MB/s    in 11s     \n",
      "\n",
      "2024-10-27 21:29:38 (20.2 MB/s) - ‘flower_photos.tgz’ saved [228813984/228813984]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJOZnXOsc4k5"
   },
   "outputs": [],
   "source": [
    "!tar  -xzf flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTtrv2uYmvzO",
    "outputId": "9c538c53-b6e1-4735-b307-6865fe023bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dandelion', 'LICENSE.txt', 'sunflowers', 'tulips', 'daisy', 'roses']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('flower_photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XVA1Bf5hm8ze"
   },
   "outputs": [],
   "source": [
    "!rm flower_photos/LICENSE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_cnWrgNa9EM",
    "outputId": "97de2902-7554-4327-c0a7-df5346807c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n",
      "898\n",
      "641\n",
      "699\n",
      "799\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('./flower_photos/daisy')))\n",
    "print(len(os.listdir('./flower_photos/dandelion')))\n",
    "print(len(os.listdir('./flower_photos/roses')))\n",
    "print(len(os.listdir('./flower_photos/sunflowers')))\n",
    "print(len(os.listdir('./flower_photos/tulips')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h6tsSNXCmk-e"
   },
   "outputs": [],
   "source": [
    "# renaming with \"type name\" and \"numbers\"\n",
    "# eg. daisy_67\n",
    "# eg. roses_600\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set the base directory\n",
    "original_flower_dir = \"./flower_photos\"\n",
    "\n",
    "random_names = [str(name) for name in range(1000)]\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Iterate through the folders in the base directory\n",
    "for folder_name in os.listdir(original_flower_dir):\n",
    "    folder_path = os.path.join(original_flower_dir, folder_name)\n",
    "\n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate through the files in the folder\n",
    "\n",
    "        count = 0\n",
    "        for filename in os.listdir(folder_path):\n",
    "\n",
    "            image_extension = filename.split(\".\")[-1]\n",
    "            new_filename = folder_name +\"_\" + f\"{str(random_names[count])}\" + \".\" + image_extension\n",
    "\n",
    "            # Construct the full paths\n",
    "            old_file_path = os.path.join(folder_path, filename)\n",
    "            new_file_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "\n",
    "            # Increment the count\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p0c6VBcXqvGm"
   },
   "outputs": [],
   "source": [
    "# making my flower dataset\n",
    "# making train and test folders in my flower dataset\n",
    "\n",
    "my_flower_dir = \"./my_flower_photos\"\n",
    "\n",
    "os.makedirs(my_flower_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(my_flower_dir, 'train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "test_dir = os.path.join(my_flower_dir, 'test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# making train folder in my flower photos\n",
    "for folder_name in os.listdir('flower_photos'):\n",
    "  dest_dir = os.path.join(train_dir, folder_name)\n",
    "  os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# making test folder in my flower photos\n",
    "for folder_name in os.listdir('flower_photos'):\n",
    "  dest_dir = os.path.join(test_dir, folder_name)\n",
    "  os.makedirs(dest_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CJCcXsDkvGPk"
   },
   "outputs": [],
   "source": [
    "# Copy first 500 images to each train directory\n",
    "\n",
    "import shutil\n",
    "\n",
    "original_flower_dir = './flower_photos'\n",
    "my_flower_dir = \"./my_flower_photos\"\n",
    "my_flower_train_dir = os.path.join(my_flower_dir, 'train')\n",
    "\n",
    "for folder_name in os.listdir(original_flower_dir):\n",
    "  fnames = [f'{folder_name}_{i}.jpg' for i in range(500)]\n",
    "  for fname in fnames:\n",
    "      src = os.path.join(os.path.join(original_flower_dir,folder_name), fname) # eg. flower_photos/daisy/daisy_41\n",
    "      dst = os.path.join(os.path.join(my_flower_train_dir,folder_name), fname) # eg. my_flower_photos/train/daisy/daisy_41\n",
    "      shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Bwl0kYHBvGbt"
   },
   "outputs": [],
   "source": [
    "# Copy 100 of remaining images to each test directory\n",
    "\n",
    "import shutil\n",
    "\n",
    "original_flower_dir = './flower_photos'\n",
    "my_flower_dir = \"./my_flower_photos\"\n",
    "my_flower_test_dir = os.path.join(my_flower_dir, 'test')\n",
    "\n",
    "for folder_name in os.listdir(original_flower_dir):\n",
    "  fnames = [f'{folder_name}_{i}.jpg' for i in range(500,600)]\n",
    "  for fname in fnames:\n",
    "      src = os.path.join(os.path.join(original_flower_dir,folder_name), fname) # eg. flower_photos/daisy/daisy_540\n",
    "      dst = os.path.join(os.path.join(my_flower_test_dir,folder_name), fname) # eg. my_flower_photos/test/daisy/daisy_540\n",
    "      shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLOnC-4I2UOK"
   },
   "source": [
    "# phase 2. : training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zkKvcUHThij",
    "outputId": "c8ba2c8a-8e6d-4a74-86d8-98fe66a7878d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "my_flower_dir = \"./my_flower_photos\"\n",
    "my_flower_train_dir = os.path.join(my_flower_dir, 'train')\n",
    "my_flower_test_dir = os.path.join(my_flower_dir, 'test')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 114\n",
    "img_width = 114\n",
    "\n",
    "# the dataset is small, so we need to do some processing on data,\n",
    "# for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    my_flower_train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    my_flower_test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9IyDuJeXIuJ"
   },
   "source": [
    "### Modifying the model for faster training \n",
    "reducing layers, and using GAP instead of flatten.  \n",
    "(it's just a practice, no high accuracy is required. By the way by using all layers we can get a higher accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ksuUs9RThkx",
    "outputId": "8e48a81d-67d3-4853-c860-ecd09da4097b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_vgg_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=(img_height, img_width, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(512, activation='relu'))\n",
    "    # model.add(layers.Dropout(0.5))\n",
    "    # model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "    # # instead of flattening, i employ global average pooling so as to reduce params\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_vgg_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "kiS5AlMrThnP",
    "outputId": "540ec4ae-dbc8-4204-bf15-82a425808009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,850</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m12,850\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m255\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,162,097</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,162,097\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,160,305</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,160,305\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uRLn0OdpThpx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqCejxubThsD",
    "outputId": "8d0de1a8-1dd8-49cb-e15e-ce5df238c6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 283ms/step - accuracy: 0.3801 - loss: 1.5379 - val_accuracy: 0.2020 - val_loss: 1.6309 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - accuracy: 0.4443 - loss: 1.4560 - val_accuracy: 0.2100 - val_loss: 1.6381 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 200ms/step - accuracy: 0.4905 - loss: 1.4031 - val_accuracy: 0.2240 - val_loss: 1.6235 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 202ms/step - accuracy: 0.4762 - loss: 1.3560 - val_accuracy: 0.3740 - val_loss: 1.4558 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 213ms/step - accuracy: 0.4856 - loss: 1.3327 - val_accuracy: 0.4700 - val_loss: 1.3384 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.4875 - loss: 1.2986 - val_accuracy: 0.4500 - val_loss: 1.3324 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.4946 - loss: 1.2860 - val_accuracy: 0.4400 - val_loss: 1.3213 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 224ms/step - accuracy: 0.4919 - loss: 1.2582 - val_accuracy: 0.5000 - val_loss: 1.2170 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.4975 - loss: 1.2324 - val_accuracy: 0.3980 - val_loss: 1.3338 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 202ms/step - accuracy: 0.4969 - loss: 1.2182 - val_accuracy: 0.4400 - val_loss: 1.2783 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.4998 - loss: 1.1962 - val_accuracy: 0.4820 - val_loss: 1.2387 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 224ms/step - accuracy: 0.5175 - loss: 1.1734 - val_accuracy: 0.5000 - val_loss: 1.2093 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - accuracy: 0.5003 - loss: 1.1899 - val_accuracy: 0.5160 - val_loss: 1.1707 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 201ms/step - accuracy: 0.5068 - loss: 1.1591 - val_accuracy: 0.4380 - val_loss: 1.3379 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.5495 - loss: 1.1147 - val_accuracy: 0.5440 - val_loss: 1.1459 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 0.5535 - loss: 1.1097 - val_accuracy: 0.5120 - val_loss: 1.1256 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 202ms/step - accuracy: 0.5744 - loss: 1.1094 - val_accuracy: 0.5740 - val_loss: 1.1242 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 203ms/step - accuracy: 0.6186 - loss: 1.0614 - val_accuracy: 0.5360 - val_loss: 1.1706 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - accuracy: 0.6133 - loss: 1.0570 - val_accuracy: 0.5820 - val_loss: 1.0620 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.6162 - loss: 1.0462 - val_accuracy: 0.5940 - val_loss: 1.0678 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 206ms/step - accuracy: 0.6385 - loss: 1.0026 - val_accuracy: 0.6260 - val_loss: 1.0869 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 0.6422 - loss: 0.9913 - val_accuracy: 0.6420 - val_loss: 0.9999 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.6168 - loss: 1.0146 - val_accuracy: 0.6080 - val_loss: 1.0517 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 206ms/step - accuracy: 0.6484 - loss: 0.9670 - val_accuracy: 0.5280 - val_loss: 1.1866 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 207ms/step - accuracy: 0.6440 - loss: 0.9697 - val_accuracy: 0.6160 - val_loss: 1.0222 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.6605 - loss: 0.9359 - val_accuracy: 0.6340 - val_loss: 0.9587 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 201ms/step - accuracy: 0.6603 - loss: 0.9247 - val_accuracy: 0.6560 - val_loss: 0.9334 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 199ms/step - accuracy: 0.6552 - loss: 0.9176 - val_accuracy: 0.6520 - val_loss: 0.9515 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 202ms/step - accuracy: 0.6764 - loss: 0.8740 - val_accuracy: 0.6120 - val_loss: 1.0055 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 206ms/step - accuracy: 0.6646 - loss: 0.9023 - val_accuracy: 0.6320 - val_loss: 0.9395 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - accuracy: 0.6789 - loss: 0.8547 - val_accuracy: 0.5640 - val_loss: 1.1278 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 209ms/step - accuracy: 0.6619 - loss: 0.8770 - val_accuracy: 0.6220 - val_loss: 0.9591 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - accuracy: 0.6536 - loss: 0.8785 - val_accuracy: 0.6860 - val_loss: 0.8564 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - accuracy: 0.6966 - loss: 0.8045 - val_accuracy: 0.6160 - val_loss: 0.9336 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 208ms/step - accuracy: 0.7025 - loss: 0.7877 - val_accuracy: 0.6700 - val_loss: 0.8488 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 208ms/step - accuracy: 0.7190 - loss: 0.7774 - val_accuracy: 0.6340 - val_loss: 0.9611 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - accuracy: 0.7171 - loss: 0.7686 - val_accuracy: 0.6260 - val_loss: 0.9498 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 211ms/step - accuracy: 0.7229 - loss: 0.7614 - val_accuracy: 0.6820 - val_loss: 0.8480 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 205ms/step - accuracy: 0.6888 - loss: 0.7771 - val_accuracy: 0.6880 - val_loss: 0.8601 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - accuracy: 0.7107 - loss: 0.7485 - val_accuracy: 0.6640 - val_loss: 0.8494 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 208ms/step - accuracy: 0.7086 - loss: 0.7678 - val_accuracy: 0.6600 - val_loss: 0.8677 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.7199 - loss: 0.7579 - val_accuracy: 0.6740 - val_loss: 0.8884 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 208ms/step - accuracy: 0.7284 - loss: 0.7289 - val_accuracy: 0.6280 - val_loss: 0.9711 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.7341 - loss: 0.7360 - val_accuracy: 0.6880 - val_loss: 0.8272 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.7347 - loss: 0.7092 - val_accuracy: 0.6880 - val_loss: 0.8231 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.7237 - loss: 0.7088 - val_accuracy: 0.7060 - val_loss: 0.8009 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7391 - loss: 0.6941 - val_accuracy: 0.7000 - val_loss: 0.8163 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 207ms/step - accuracy: 0.7452 - loss: 0.6978 - val_accuracy: 0.7020 - val_loss: 0.8099 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 208ms/step - accuracy: 0.7494 - loss: 0.6908 - val_accuracy: 0.6940 - val_loss: 0.8126 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 211ms/step - accuracy: 0.7442 - loss: 0.6956 - val_accuracy: 0.7180 - val_loss: 0.7788 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 209ms/step - accuracy: 0.7421 - loss: 0.7073 - val_accuracy: 0.6820 - val_loss: 0.8214 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 207ms/step - accuracy: 0.7647 - loss: 0.6442 - val_accuracy: 0.7040 - val_loss: 0.7761 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - accuracy: 0.7481 - loss: 0.6550 - val_accuracy: 0.7020 - val_loss: 0.8077 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7633 - loss: 0.6605 - val_accuracy: 0.6980 - val_loss: 0.7757 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7524 - loss: 0.6659 - val_accuracy: 0.6800 - val_loss: 0.8136 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.7590 - loss: 0.6512 - val_accuracy: 0.7080 - val_loss: 0.7876 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7525 - loss: 0.6508 - val_accuracy: 0.6840 - val_loss: 0.7884 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 213ms/step - accuracy: 0.7521 - loss: 0.6629 - val_accuracy: 0.6980 - val_loss: 0.7727 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 206ms/step - accuracy: 0.7694 - loss: 0.6236 - val_accuracy: 0.7000 - val_loss: 0.7882 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 0.7615 - loss: 0.6276 - val_accuracy: 0.7020 - val_loss: 0.7604 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 203ms/step - accuracy: 0.7652 - loss: 0.6337 - val_accuracy: 0.7280 - val_loss: 0.7721 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.7635 - loss: 0.6260 - val_accuracy: 0.6960 - val_loss: 0.8034 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.7590 - loss: 0.6419 - val_accuracy: 0.7100 - val_loss: 0.8060 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 223ms/step - accuracy: 0.7763 - loss: 0.6178 - val_accuracy: 0.7140 - val_loss: 0.7460 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 209ms/step - accuracy: 0.7745 - loss: 0.5948 - val_accuracy: 0.7160 - val_loss: 0.7925 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7646 - loss: 0.6345 - val_accuracy: 0.7180 - val_loss: 0.7448 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 223ms/step - accuracy: 0.7817 - loss: 0.5947 - val_accuracy: 0.7500 - val_loss: 0.7585 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 205ms/step - accuracy: 0.7979 - loss: 0.6065 - val_accuracy: 0.7320 - val_loss: 0.8057 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 207ms/step - accuracy: 0.8013 - loss: 0.5884 - val_accuracy: 0.7340 - val_loss: 0.7658 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 227ms/step - accuracy: 0.7768 - loss: 0.5873 - val_accuracy: 0.7600 - val_loss: 0.7236 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 209ms/step - accuracy: 0.7928 - loss: 0.5751 - val_accuracy: 0.7700 - val_loss: 0.7168 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7875 - loss: 0.5925 - val_accuracy: 0.7320 - val_loss: 0.7644 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 226ms/step - accuracy: 0.7957 - loss: 0.5816 - val_accuracy: 0.7080 - val_loss: 0.7501 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 207ms/step - accuracy: 0.7930 - loss: 0.6024 - val_accuracy: 0.7580 - val_loss: 0.7370 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.8002 - loss: 0.5850 - val_accuracy: 0.7720 - val_loss: 0.7148 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 0.8084 - loss: 0.5837 - val_accuracy: 0.7640 - val_loss: 0.7236 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.7976 - loss: 0.5839 - val_accuracy: 0.7520 - val_loss: 0.7475 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 202ms/step - accuracy: 0.8210 - loss: 0.5542 - val_accuracy: 0.7580 - val_loss: 0.7269 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 202ms/step - accuracy: 0.7972 - loss: 0.5979 - val_accuracy: 0.7600 - val_loss: 0.7117 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 200ms/step - accuracy: 0.8306 - loss: 0.5307 - val_accuracy: 0.7640 - val_loss: 0.7228 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - accuracy: 0.8097 - loss: 0.5527 - val_accuracy: 0.7540 - val_loss: 0.7265 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 206ms/step - accuracy: 0.8243 - loss: 0.5391 - val_accuracy: 0.7380 - val_loss: 0.7463 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 200ms/step - accuracy: 0.8330 - loss: 0.5266 - val_accuracy: 0.7520 - val_loss: 0.7505 - learning_rate: 2.5000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 222ms/step - accuracy: 0.8145 - loss: 0.5373 - val_accuracy: 0.7860 - val_loss: 0.6662 - learning_rate: 2.5000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.8131 - loss: 0.5585 - val_accuracy: 0.7300 - val_loss: 0.7874 - learning_rate: 2.5000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.8278 - loss: 0.5444 - val_accuracy: 0.7460 - val_loss: 0.6979 - learning_rate: 2.5000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - accuracy: 0.8395 - loss: 0.5207 - val_accuracy: 0.7540 - val_loss: 0.7216 - learning_rate: 2.5000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 211ms/step - accuracy: 0.8262 - loss: 0.5347 - val_accuracy: 0.7640 - val_loss: 0.7075 - learning_rate: 2.5000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 201ms/step - accuracy: 0.8543 - loss: 0.4901 - val_accuracy: 0.7320 - val_loss: 0.7912 - learning_rate: 2.5000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.8155 - loss: 0.5176 - val_accuracy: 0.7900 - val_loss: 0.6584 - learning_rate: 1.2500e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.8446 - loss: 0.5116 - val_accuracy: 0.7760 - val_loss: 0.6557 - learning_rate: 1.2500e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 223ms/step - accuracy: 0.8607 - loss: 0.4671 - val_accuracy: 0.7860 - val_loss: 0.6646 - learning_rate: 1.2500e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 207ms/step - accuracy: 0.8525 - loss: 0.4759 - val_accuracy: 0.7860 - val_loss: 0.6729 - learning_rate: 1.2500e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.8550 - loss: 0.4739 - val_accuracy: 0.7780 - val_loss: 0.6833 - learning_rate: 1.2500e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 204ms/step - accuracy: 0.8385 - loss: 0.4952 - val_accuracy: 0.7980 - val_loss: 0.6486 - learning_rate: 1.2500e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.8591 - loss: 0.4594 - val_accuracy: 0.7680 - val_loss: 0.7042 - learning_rate: 1.2500e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.8539 - loss: 0.4717 - val_accuracy: 0.7860 - val_loss: 0.6522 - learning_rate: 1.2500e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 204ms/step - accuracy: 0.8683 - loss: 0.4590 - val_accuracy: 0.7760 - val_loss: 0.6611 - learning_rate: 1.2500e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 0.8708 - loss: 0.4550 - val_accuracy: 0.7720 - val_loss: 0.6853 - learning_rate: 1.2500e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 211ms/step - accuracy: 0.8586 - loss: 0.4616 - val_accuracy: 0.7860 - val_loss: 0.6531 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bhd4-4m52-O",
    "outputId": "76ad23f3-f390-4871-e015-b285a1102a4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('./vgg_flower_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AZ1oqtkAXIr",
    "outputId": "bfd6c4d8-2719-4512-c8fe-85f0824ba4ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('drive/MyDrive/vgg_flower_2.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
