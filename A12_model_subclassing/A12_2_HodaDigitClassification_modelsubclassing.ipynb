{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c3e8fb; padding: 10px; color: #144d84;\">\n",
    "<b>Exercise 2) Model Subclassing for Persian Number Classification</b><br>\n",
    "Write a convolutional neural network for classifying Persian numbers using batch normalization and residual connections. This network must use model subclassing, and its accuracy on the evaluation dataset should not be below 98%.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "vBRZX-C750Qt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# cv2 and io for loading hoda\n",
    "import cv2\n",
    "from scipy import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "TTum29Cm51Us"
   },
   "outputs": [],
   "source": [
    "def load_hoda(training_sample_size=1000, test_sample_size=200, size=5):\n",
    "    #load dataset\n",
    "    trs = training_sample_size\n",
    "    tes = test_sample_size\n",
    "    dataset = io.loadmat('Data_hoda_full.mat')\n",
    "\n",
    "    #test and training set\n",
    "    X_train_orginal = np.squeeze(dataset['Data'][:trs])\n",
    "    y_train = np.squeeze(dataset['labels'][:trs])\n",
    "    X_test_original = np.squeeze(dataset['Data'][trs:trs+tes])\n",
    "    y_test = np.squeeze(dataset['labels'][trs:trs+tes])\n",
    "\n",
    "    #resize\n",
    "    X_train_5by5 = [cv2.resize(img, dsize=(size, size)) for img in X_train_orginal]\n",
    "    X_test_5by_5 = [cv2.resize(img, dsize=(size, size)) for img in X_test_original]\n",
    "    #reshape\n",
    "    X_train = np.reshape(X_train_5by5, [-1,size**2])\n",
    "    X_test = np.reshape(X_test_5by_5, [-1,size**2])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "svRrBKUl556K"
   },
   "outputs": [],
   "source": [
    "hw = 30\n",
    "x_train, y_train, x_test, y_test = load_hoda(training_sample_size=1000, test_sample_size=200, size=hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "yarcJz2_8kBx"
   },
   "outputs": [],
   "source": [
    "x_train= x_train.reshape(-1, hw, hw, 1)\n",
    "x_test= x_test.reshape(-1, hw, hw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6P94-rf8kEo",
    "outputId": "2638d00f-c9b5-4e48-e4ab-1d20d099e90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "TjjBYQU6-mnl"
   },
   "outputs": [],
   "source": [
    "class HodaModel(Model):\n",
    "    def __init__(self):\n",
    "        super(HodaModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.conv2 = Conv2D(32, (3, 3), activation=None, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')\n",
    "        self.bn3 = BatchNormalization()\n",
    "\n",
    "        self.conv4 = Conv2D(64, (3, 3), activation=None, padding='same')\n",
    "        self.bn4 = BatchNormalization()\n",
    "\n",
    "        self.max_pool = MaxPooling2D((2, 2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def residual_block(self, x, conv, bn, filters):\n",
    "        y = conv(x)\n",
    "        y = bn(y)\n",
    "        y = tf.nn.relu(y)\n",
    "        return y + x\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # residual connection\n",
    "        x = self.residual_block(x, self.conv2, self.bn2, 32)\n",
    "\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # residual connection\n",
    "        x = self.residual_block(x, self.conv4, self.bn4, 64)\n",
    "\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = HodaModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uosj-MiJMmMW",
    "outputId": "8e776d5d-7e50-40b2-f697-5bd3aaf30f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.3272 - loss: 1.9518 - val_accuracy: 0.8300 - val_loss: 0.5583\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8269 - loss: 0.5566 - val_accuracy: 0.8500 - val_loss: 0.4587\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8971 - loss: 0.3452 - val_accuracy: 0.9250 - val_loss: 0.2388\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9318 - loss: 0.2235 - val_accuracy: 0.9650 - val_loss: 0.1889\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9494 - loss: 0.1449 - val_accuracy: 0.9550 - val_loss: 0.1411\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9599 - loss: 0.1144 - val_accuracy: 0.9650 - val_loss: 0.1439\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9734 - loss: 0.0698 - val_accuracy: 0.9700 - val_loss: 0.1307\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9848 - loss: 0.0485 - val_accuracy: 0.9800 - val_loss: 0.1253\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9873 - loss: 0.0387 - val_accuracy: 0.9550 - val_loss: 0.1419\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9982 - loss: 0.0173 - val_accuracy: 0.9650 - val_loss: 0.1709\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0169 - val_accuracy: 0.9650 - val_loss: 0.1403\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0075 - val_accuracy: 0.9600 - val_loss: 0.1641\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9750 - val_loss: 0.1533\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9650 - val_loss: 0.1508\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9600 - val_loss: 0.1916\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9700 - val_loss: 0.1649\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9700 - val_loss: 0.1770\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9700 - val_loss: 0.1763\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe25c464f40>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKd3pF-N-mp4",
    "outputId": "05016d4f-20c6-484c-a349-bc89fee24ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.1178 \n",
      "acc on test data: 0.98\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'acc on test data: {test_acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
